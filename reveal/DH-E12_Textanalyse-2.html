<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<!-- CUSTOMIZE THIS! -->
<title>Einführung in die Digital Humanities</title>
<meta name="author" content="Christof Schöch">
<!-- END -->
<meta name="description" content="Slides">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
<link rel="stylesheet" href="css/reveal.css">
<link rel="stylesheet" href="css/theme/simple.css" id="theme">
<!-- Code syntax highlighting -->
<link rel="stylesheet" href="lib/css/zenburn.css">
<!-- Printing and PDF exports -->
<script>
var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>
<!--[if lt IE 9]>
<script src="lib/js/html5shiv.js"></script>
<![endif]-->
</head>

<body>
<div class="reveal">
<div class="slides">
<section data-markdown="" data-separator="^\n-\n" data-separator-vertical="^\n--\n" data-charset="utf-8" data-background-image="img/basics/uni-trier-mini.png" data-background-size="50px" data-background-position="top right">
<script type="text/template">

<br/>
## Quantitative Textanalyse 2: Maschinelles Lernen
<hr/>
<br/>
<br/>Vorlesung *Einführung in die Digital Humanities*
<br/>MSc Digital Humanities | Wintersemester 2019/20
<br/>
<br/>Prof. Dr. Christof Schöch
<br/>
<br/>
<hr/>
<br/><img height="50" data-src="img/basics/uni-trier.png">


-
# Einstieg

--
## Semesterüberblick

<small>

* 29.10.: Digital Humanities im Überblick
* 05.11.: Digitalisierung: Text und Bild
* 12.11.: Grundbegriffe des Programmierens
* 19.11.: Datenmodellierung 1: Modellierung
* 26.11.: Datenmodellierung 2: Datenbanken
* 03.12.: Datenmodellierung 3: Text, Markup, XML
* 10.12.: Digitale Edition
* 17.12.: Geschichte der Digital Humanities
* 21.12.-5.1.: *Weihnachtspause*
* 07.01.: Informationsvisualisierung
* 14.01.: Natural Language Processing
* 21.01.: Quantitative Analyse 1: Stilometrie
* **28.01.: Quantitative Analyse 2: Superv. Machine Learning**
* 04.02.: Open Humanities
* 11.02.: Klausurtermin

</small>

--
## Sitzungsüberblick
1. Machine Learning (ML)
2. Überwachtes ML: Einstieg
3. Überwachtes ML: Anwendungsbeispiel
4. Überwachtes ML: verschiedene "Classifier"
5. Was ist Deep Learning?


-
# 1. Machine Learning

--
## Zwei Typen von ML
|unüberwacht /<br/> unsupervised|überwacht /<br/>supervised|
|-----------|---------|
|Clustering|Klassifikation|
|Bilden von Gruppen|Zuordnung zu Klassen|
|keine Klassen|vorher bekannte Klassen|
|ein Datensatz|Training/Test/Anwendung|
|eher explorativ|hypothesengeleitet|
|Evaluation möglich|Evaluation leicht|
|Topic Modeling<br/>PCA, CA|Annotation<br/>OCR, NER|



-
# 2. Überwachtes ML: Einstieg

--
## Szenario: Fahrradverkauf
<img height="350" data-src="img/E12/fahrrad.jpg"></img>
* Was ist ein angemessener Preis für Ihr Fahrrad?
* Marktanalyse: andere Fahrradverkäufe
* Merkmale der Räder und Preis

--
## Daten: Merkmale und Preise

|Farbe|Gänge| Typ    |Zustand|Preis|
|-----|-----|--------|-------|-----|
|blau | 8   | MTB    | gut   | 150 |
|grün | 3   | City   | super |  95 |
|rot  | 14  | Rennrad|rep.bed.| 85 |


-
# 3. Überwachtes ML: Anwendungsbeispiel

--
## Projektseminar: Albencover
<p><a href="img/E12/1990_67ebbc43-0415-4a07-90b9-3f8f8be296eb_hip-hop-xxx.jpg"><img height="220" data-src="img/E12/1990_67ebbc43-0415-4a07-90b9-3f8f8be296eb_hip-hop-xxx.jpg"></img></a>&nbsp;&nbsp; &nbsp; &nbsp;
<a href="img/E12/1990_83219409-a39c-3c3c-9928-06f0eac04423_electronic-xxx.jpg"><img height="220" data-src="img/E12/1990_83219409-a39c-3c3c-9928-06f0eac04423_electronic-xxx.jpg"></img></a></p>
<p><a href="img/E12/1991_464721f0-91a9-42fc-b286-904106fce287_country-xxx.jpg"><img height="220" data-src="img/E12/1991_464721f0-91a9-42fc-b286-904106fce287_country-xxx.jpg"></img></a>&nbsp; &nbsp; &nbsp; &nbsp;
<a href="img/E12/2001_73bb810c-5d15-45ef-8de9-65e38b1238f6_electronic-xxx.jpg"><img height="220" data-src="img/E12/2001_73bb810c-5d15-45ef-8de9-65e38b1238f6_electronic-xxx.jpg"></img></a></p>
<p>Klassifikation: Rock, Pop, Hip-Hop, Country, Electronic.<br/>Quelle: https://musicbrainz.org/</p>



--
## Prototypischer Ablauf
1. Vorbereitung (Gegenstand, Fragestellung) <!-- .element: class="fragment" data-fragment-index="1" -->
2. Datensammlung erstellen  <!-- .element: class="fragment" data-fragment-index="2" --> 
3. Annotieren nach Klassen (Teil) <!-- .element: class="fragment" data-fragment-index="3" -->
4. Merkmale generieren <!-- .element: class="fragment" data-fragment-index="4" -->
5. Trainingsphase <!-- .element: class="fragment" data-fragment-index="5" -->
6. Evaluationsphase <!-- .element: class="fragment" data-fragment-index="6" -->
7. Anwendungsphase (Datensätze ohne Klasse) <!-- .element: class="fragment" data-fragment-index="7" -->
8. Interpretation der Ergebnisse <!-- .element: class="fragment" data-fragment-index="8" -->

--
## (1) Vorbereitung
* Annahme: Musiker sind Künstler, denen auch die künstlerische Gestaltung ihrer Albumcovers wichtig ist <!-- .element: class="fragment" data-fragment-index="1" --> 
* Hypothese: Es gibt einen Zusammenhang zwischen Musikrichtung und Cover Art <!-- .element: class="fragment" data-fragment-index="2" -->
* Aufgabe: Albencover nach Musikrichtung klassifizieren <!-- .element: class="fragment" data-fragment-index="3" -->
* Nur auf Grundlage der visuellen Information <!-- .element: class="fragment" data-fragment-index="4" -->
* Bei fünf Genres: Zufallsbaseline 20%, Human Baseline: knapp 50% <!-- .element: class="fragment" data-fragment-index="5" -->

--
## (2) Datensammlung erstellen
* Datenquelle: musicbrainz.org, Abruf über API <!-- .element: class="fragment" data-fragment-index="1" -->
* Struktur: Fünf Genres<br/>Rock, Pop, Electronic, Hip-Hop, Country <!-- .element: class="fragment" data-fragment-index="2" -->
* Umfang: 5 x 3.000 = 15.000 Albumcover <!-- .element: class="fragment" data-fragment-index="3" -->
* Daten: Bilddatei und Metadaten<br/> (Jahr, Titel, Band, Genre) <!-- .element: class="fragment" data-fragment-index="4" -->


--
## Beispiele für Cover
<p><a href="img/E12/1990_67ebbc43-0415-4a07-90b9-3f8f8be296eb_hip-hop-xxx.jpg"><img height="220" data-src="img/E12/1990_67ebbc43-0415-4a07-90b9-3f8f8be296eb_hip-hop-xxx.jpg"></img></a>&nbsp;&nbsp; &nbsp; &nbsp;
<a href="img/E12/1990_83219409-a39c-3c3c-9928-06f0eac04423_electronic-xxx.jpg"><img height="220" data-src="img/E12/1990_83219409-a39c-3c3c-9928-06f0eac04423_electronic-xxx.jpg"></img></a></p>
<p><a href="img/E12/1991_464721f0-91a9-42fc-b286-904106fce287_country-xxx.jpg"><img height="220" data-src="img/E12/1991_464721f0-91a9-42fc-b286-904106fce287_country-xxx.jpg"></img></a>&nbsp; &nbsp; &nbsp; &nbsp;
<a href="img/E12/2001_73bb810c-5d15-45ef-8de9-65e38b1238f6_electronic-xxx.jpg"><img height="220" data-src="img/E12/2001_73bb810c-5d15-45ef-8de9-65e38b1238f6_electronic-xxx.jpg"></img></a></p>
Quelle: https://musicbrainz.org/

--
## (3) Annotieren nach Klassen
* Jedes Album wird einer Musikrichtung zugeordnet
* Wir übernehmen die Zuordnung von Musicbrainz

--
## (4) Merkmale generieren 
* Einfach <!-- .element: class="fragment" data-fragment-index="1" -->
    * Dominante Farben (Histogramm des HSV-Farbraums)
    * Sättigung und Helligkeit (HSV-Farbraum)
* Komplex <!-- .element: class="fragment" data-fragment-index="2" -->
    * Anzahl der Gesichter (OpenCV)
    * Welche Objekte sind sichtbar (ClarifAI API)
* Daten in einer Merkmals-Matrix zusammengefasst <!-- .element: class="fragment" data-fragment-index="3" -->
* Optional: Merkmalsskalierung (z-scores) <!-- .element: class="fragment" data-fragment-index="4" -->

--
## (5) Merkmals-Matrix
<a href="img/E12/musicovers-matrix.png"><img height="500" data-src="img/E12/musicovers-matrix.png"></img></a>

--
## (5) Trainingsphase
* Ein Teil der gelabelten Daten (bspw. 90%) zum "Trainieren"  <!-- .element: class="fragment" data-fragment-index="1" -->
* Algorithmus "lernt" einen Zusammenhang zwischen Merkmalen und Klassen <!-- .element: class="fragment" data-fragment-index="2" -->
* Verschiedene "Classifier" mit ihren Parametern <!-- .element: class="fragment" data-fragment-index="3" -->
* Bspw. "k-nearest neighbor" <!-- .element: class="fragment" data-fragment-index="4" -->

--
## (6) Evaluationsphase
* Rest der Daten (10%) zur Evaluation <!-- .element: class="fragment" data-fragment-index="1" -->
* Vergleich der tatsächlichen Klasse mit der vom Algorithmus ernmittelten Klasse <!-- .element: class="fragment" data-fragment-index="2" -->
* F-Score <!-- .element: class="fragment" data-fragment-index="3" -->
    * Precision: welcher Anteil der als "Pop" erkannten Alben sind tatsächlich "Pop"
    * Recall: welcher Anteil der Pop-Alben wurden als solche erkannt?
    * F-Score: 2 x (precision x recall) / (precision + recall)
* Confusion Matrix <!-- .element: class="fragment" data-fragment-index="4" -->

--
## (6) Confusion Matrix
<p><a href="img/E12/XEV-006_tree-028.svg"><img height="500" data-src="img/E12/XEV-006_tree-028.svg"></img></a></p>

--
## 7. Anwendungsphase
* Entfällt in diesem Beispiel, weil alle Daten gelabelt sind
* Man könnte jetzt aber für weitere Alben Genrelabels vergeben

--
## 8. Interpretation der Ergebnisse
* Wie stark ist der angenommene<br/> Zusammenhang Cover / Genre?  <!-- .element: class="fragment" data-fragment-index="1" -->
* Gibt es Unterschiede zwischen den Genres? <!-- .element: class="fragment" data-fragment-index="2" -->
* Sind die Klassen wirklich disjunkt? <!-- .element: class="fragment" data-fragment-index="3" -->
* Welche Merkmale sind entscheidend? <!-- .element: class="fragment" data-fragment-index="4" -->


-
# 4. Verschiedene "Classifier"

--
## Classifier: k-nn
<p><a href="img/E12/knn.jpg"><img height="450" data-src="img/E12/knn.jpg"></img></a></p>
<p><small>Quelle: Struyf, Jan; Dobrin, Seth; Page, David: "Combining gene expression, demographic and clinical data in modeling disease: A case study of bipolar disorder and schizophrenia", https://www.researchgate.net/figure/Illustration-of-the-a-support-vector-machines-b-nearest-shrunken-centroids-c_fig1_23459323, Lizenz <a href="https://creativecommons.org/licenses/by/2.0/">CC-BY</a></small></p>

--
## Classifier: SVM
<p><a href="img/E12/svm-2dims_alt.png"><img height="450" data-src="img/E12/svm-2dims_alt.png"></img></a></p>
<p><small>Bildquelle: "A Linear Support Vector Machine", 2014: https://randomforests.wordpress.com/2014/01/29/a-linear-support-vector-machine/</small></p>

--
## Classifier: Decision Tree
<p><a href="img/E12/decision_tree.jpg"><img height="450" data-src="img/E12/decision_tree.jpg"></img></a></p>
<p><small>Quelle: Struyf, Jan; Dobrin, Seth; Page, David: "Combining gene expression, demographic and clinical data in modeling disease: A case study of bipolar disorder and schizophrenia", https://www.researchgate.net/figure/Illustration-of-the-a-support-vector-machines-b-nearest-shrunken-centroids-c_fig1_23459323, Lizenz <a href="https://creativecommons.org/licenses/by/2.0/">CC-BY</a></small></p>




-
# 5. Deep Learning

--
## Was ist Deep Learning?
* Deep Learning: ML mit "deep artificial neural networks" <!-- .element: class="fragment" data-fragment-index="1" -->
* Künstliche neuronale Netze: modellieren Verhalten von Nervenzellen <!-- .element: class="fragment" data-fragment-index="2" -->
* "deep": viele verborgene Schichten <!-- .element: class="fragment" data-fragment-index="3" -->
* Berechnung läuft häufig auf GPUs <!-- .element: class="fragment" data-fragment-index="4" -->
* erfordert sehr große Datensätze <!-- .element: class="fragment" data-fragment-index="5" -->
* nützlich bei komplexen Zusammenhängen zwischen Input und Output <!-- .element: class="fragment" data-fragment-index="6" -->
* Anwendungsbereiche: Schach, Go, Spracherkennung, autonomes Fahren, uvm.  <!-- .element: class="fragment" data-fragment-index="7" -->

--
##Einfaches neuronales Netz
<img height="400" data-src="img/E12/neural-networks.png"></img>
<br/>
<small>(Source: User Chrislb, https://commons.wikimedia.org/wiki/File:MultiLayerNeuralNetworkBigger_english.png, [CC BY-SA](https://creativecommons.org/licenses/by-sa/3.0/deed.en))</small>


-
# Abschluss

--
## Fragen?

--
## Lektürehinweise
<small>
    
* Christof Schöch, "Quantitative Analyse", in: *Digital Humanities: Eine Einführung*. Hrsg. von Fotis Jannidis, Hubertus Kohle, Malte Rehbein. Stuttgart: Metzler.
<br/>
<br/>
**Weitere Empfehlungen**
* John D. Kelleher. *Deep Learning*. Cambridge MA: MIT Press, 2019.
* Alpaydin, E. (2010). _Introduction to Machine Learning_. 2nd ed. Cambridge, Mass: MIT Press.
* Ramsay, Stephen (2011). _Reading Machines : Toward an Algorithmic Criticism_. Urbana  Ill.: University of Illinois Press.

</small>

--
## Nächste Sitzung
<br/>
* 1.2.2018 (letzte Sitzung vor der Klausur)
* Mein Themenvorschlag: "Open Humanities"
* Vorbereitung: "Informationen zu Open Access"<br/>(mit den Unterpunkten im Menü):<br/> http://open-access.net/informationen-zu-open-access/


-
<br/>
<br/>
<br/>
<br/>
<br/>Christof Schöch, 2020
<br/>http://www.christof-schoech.de
<br/>
<hr/>
Lizenz: [Creative Commons Attribution 4.0](https://creativecommons.org/licenses/by/4.0/)
<br/>


</script>

<!-- DON'T TOUCH UNLESS YOU KNOW WHAT YOU'RE DOING :-) -->
</div>
<script src="lib/js/head.min.js"></script>
<script src="js/reveal.js"></script>
<script>
// Full list of configuration options available at:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({
    controls: true,
    progress: true,
    history: true,
    center: true,
    transition: 'slide', // none/fade/slide/convex/concave/zoom
    // Optional reveal.js plugins
    dependencies: [
        { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
        { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
        { src: 'plugin/zoom-js/zoom.js', async: true },
        { src: 'plugin/notes/notes.js', async: true }
        ]
    });
Reveal.configure({ slideNumber: true });
</script>
</body>
</html>
